# Road-Extraction-DL
Comparative analysis of deep learning models (U-Net, ResUNet, VGG16 U-Net, Self-Attention U-Net, Custom CNN) for road extraction from satellite imagery using the DeepGlobe dataset.
# ğŸš§ Road Extraction from Satellite Imagery using Deep Learning

### ğŸ” Semantic Segmentation with U-Net, ResUNet, VGG16 U-Net, Self-Attention U-Net, and Custom CNN

---

## ğŸ“Œ Overview

This project implements and compares five deep learning models for road extraction from high-resolution satellite imagery using semantic segmentation. It uses the **DeepGlobe Road Extraction** dataset and evaluates each model on both qualitative and quantitative metrics.

---

## ğŸ›° Dataset

- **Source:** DeepGlobe Road Extraction Dataset
- **Images:** 6,208 RGB satellite images (JPEG)
- **Masks:** Binary grayscale masks (PNG, road = 1, background = 0)
- **Split:** 90% Training (5,600), 10% Validation (608)
- **Preprocessing:**
  - Resized to 256Ã—256 using LANCZOS resampling
  - Normalized to [0, 1]
  - Custom data generator used for batching and augmentation

---

## ğŸ§  Models Implemented

| Model                | Description                                                 |
|---------------------|-------------------------------------------------------------|
| **U-Net**            | Baseline encoder-decoder with skip connections              |
| **Custom CNN**       | Lightweight architecture for faster training and inference  |
| **ResUNet**          | Adds residual blocks for better gradient flow and edge detail |
| **VGG16 U-Net**      | U-Net with pretrained VGG16 encoder for transfer learning   |
| **Self-Attention U-Net** | Integrates attention to capture long-range spatial dependencies |

---

## âš™ï¸ Training Configuration

- **Environment:** Google Colab (TPU/GPU)
- **Loss Function:** Binary Crossentropy (BCE), with Dice Loss for VGG16 in some runs
- **Optimizers:** Adam, SGD
- **Batch Sizes:** 4â€“16
- **Epochs:** 8â€“50
- **Callbacks Used:** `EarlyStopping`, `ReduceLROnPlateau`, `ModelCheckpoint`, `CSVLogger`

---

## ğŸ“Š Evaluation Metrics

- **Primary:** Intersection over Union (IoU)
- **Secondary:** Pixel Accuracy (used for trends only)

| Model               | Epochs | Performance Summary                                  |
|--------------------|--------|------------------------------------------------------|
| U-Net              | 8      | Moderate segmentation with road discontinuities      |
| Custom CNN         | 25     | Better continuity, some false positives              |
| ResUNet            | 10     | Fragmented output due to undertraining               |
| VGG16 U-Net        | 10     | Sharp edges but mild over-segmentation               |
| Self-Attention U-Net | 25   | Most accurate and connected segmentation             |

---

## ğŸ–¼ Qualitative Analysis

Visual inspection of predictions was conducted using an unlabeled test set to assess:
- Road continuity and connectivity
- Edge sharpness
- False positives and noise resilience

*(See `/results/` or report for outputs)*

---

## ğŸ”¬ Comparative Summary

âœ… **Best Overall Performance:** Self-Attention U-Net  
ğŸ“Œ **Observations:**
- **Custom CNN**: Fast but less precise
- **VGG16 U-Net**: High feature quality, prone to over-segmentation
- **U-Net / ResUNet**: Need more epochs to improve

---

## ğŸ”­ Future Work

- Incorporate transformer-based segmentation (e.g., SAM, Mask2Former)
- Add CRF or graph-based post-processing
- Deploy as a web app using Streamlit or Gradio
- Explore ensembling methods

## ğŸ“ Project Structure

```
road-extraction-deep-learning/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                   # Training images and masks
â”‚   â”œâ”€â”€ val/                     # Validation images and masks
â”‚   â””â”€â”€ test/                    # Test images (no ground truth)
â”‚
â”œâ”€â”€ models/                      # Model architecture scripts
â”‚   â”œâ”€â”€ unet.py
â”‚   â”œâ”€â”€ resunet.py
â”‚   â”œâ”€â”€ custom_cnn.py
â”‚   â”œâ”€â”€ vgg16_unet.py
â”‚   â””â”€â”€ attention_unet.py
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for each model
â”‚   â”œâ”€â”€ train_unet.ipynb
â”‚   â”œâ”€â”€ train_resunet.ipynb
â”‚   â”œâ”€â”€ train_custom_cnn.ipynb
â”‚   â”œâ”€â”€ train_vgg16_unet.ipynb
â”‚   â””â”€â”€ train_attention_unet.ipynb
â”‚
â”œâ”€â”€ utils/                       # Utility scripts (data loaders, metrics, etc.)
â”‚   â”œâ”€â”€ data_generator.py
â”‚   â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ results/                     # Output predictions and training logs
â”‚   â”œâ”€â”€ qualitative_outputs/     # Predicted masks from test images
â”‚   â””â”€â”€ training_logs/           # CSV logs, model checkpoints
â”‚
â”œâ”€â”€ report/
â”‚   â””â”€â”€ Road Extraction - Final Report.pdf
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt             # (Optional) Python package list
```


## ğŸ“„ Report & Resources

- ğŸ“˜ **[Download Final Report](./report/Road Extraction - Final Report.pdf)**  
- ğŸ“‚ Trained model weights: _[To be added if available]_  
- ğŸ’» Full code and notebooks for each model in `/notebooks/`

